{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/' # Define the input and output directories\nOUTPUT_DIR = './'\n# Check if the output directory exists, and create it if it doesn't\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    # number of worker threads to use for data loading\n    num_workers = 4\n    # path to input data directory\n    input_path = \"../input/us-patent-phrase-to-phrase-matching/\"\n    # path to configuration file\n    config_path = input_path + \"config.pth\"\n    # path to pre-trained model\n    model_path = \"../input/uspppm-debertv3large-5folds-v2/\"\n    # batch size for training\n    batch_size = 32\n    # dropout probability for fully-connected layer\n    fc_dropout = 0.2\n    # number of target classes (in this case, 1 for regression)\n    target_size = 1\n    # maximum sequence length for input tokens\n    max_len = 133\n    # random seed for reproducibility\n    seed = 42\n    # number of folds for cross-validation\n    n_fold = 4\n    # indices of training folds\n    trn_fold = [0, 1, 2, 3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\nimport tokenizers\nimport transformers,datasets\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig,TrainingArguments, Trainer\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom logging import getLogger, INFO, StreamHandler, FileHandler, Formatter","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A function to calculate the Pearson Correaltion coefficient of the \"anchor\" and \"target\" features\ndef get_score(y_true, y_pred):\n    \"\"\"\n    Computes the Pearson correlation coefficient between the true and predicted labels.\n\n    Args:\n    - y_true: array-like of shape (n_samples,) - True labels of the data.\n    - y_pred: array-like of shape (n_samples,) - Predicted labels of the data.\n\n    Returns:\n    - score: float - The Pearson correlation coefficient between the true and predicted labels.\n    \"\"\"\n    score = sp.stats.pearsonr(y_true, y_pred)[0]  # Compute Pearson correlation coefficient\n    return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_logger(filename=OUTPUT_DIR+'train'):\n    # create a logger object with the name of the current module\n    logger = getLogger(__name__)\n    # set the logging level to INFO\n    logger.setLevel(INFO)\n    # create a StreamHandler to output log messages to the console\n    handler1 = StreamHandler()\n    # set the format for the log messages\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    # create a FileHandler to output log messages to a file\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    # set the format for the log messages\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    # add both handlers to the logger object\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    # return the logger object\n    return logger","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nLOGGER = get_logger()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# oof_df = pd.read_pickle(CFG.path+'oof_df.csv')\n# labels = oof_df['score'].values\n# preds = oof_df['pred'].values\n# score = get_score(labels, preds)\n# LOGGER.info(f'CV Score: {score:<.4f}')\n\ntest_df = pd.read_csv(f\"{CFG.input_path}test.csv\") # Import the public test data set\ntitles = pd.read_csv('../input/cpc-codes/titles.csv') # Import the CPC Classification file\ntest_df = test_df.merge(titles, left_on='context', right_on='code') # Merge the test and CPC Classification datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['input'] = test_df['title']+'[SEP]'+test_df['anchor'] # Creates a new column 'input' to be used in further analysis","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load tokenizer from the specified pre-trained model path\ntokenizer = AutoTokenizer.from_pretrained(f'{CFG.model_path}uspppm_0')\n# This piggybacks on the pre-trained DeBERTa model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class InferDataset(Dataset):\n    def __init__(self, df):\n        # convert input and target columns to string type and store them in the inputs and targets arrays respectively\n        self.inputs = df['input'].values.astype(str)\n        self.targets = df['target'].values.astype(str)\n\n    def __len__(self):\n        # return the number of inputs\n        return len(self.inputs)\n\n    def __getitem__(self, item):\n        # get the inputs and targets for the given item\n        inputs = self.inputs[item]\n        targets = self.targets[item]\n        \n        # return a dictionary containing the tokenized inputs and targets\n        return {\n        **tokenizer( inputs, targets )\n    }\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_score(eval_pred):\n    # extract predictions and labels from the input\n    predictions, labels = eval_pred\n    # reshape predictions to be of length equal to the number of predictions\n    predictions = predictions.reshape(len(predictions))\n    # compute Pearson correlation coefficient between predictions and labels\n    pearson_corr = np.corrcoef(predictions, labels)[0][1]\n    # return dictionary containing the computed score\n    return {'pearson': pearson_corr}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initialize an empty list to store the predictions for each fold\npredictions = []\n\n# loop over each fold\nfor fold in range(CFG.n_fold):\n    \n    # create an instance of the InferDataset class using the test data\n    te_dataset = InferDataset(test_df)\n    \n    # load the trained model for the current fold\n    model = AutoModelForSequenceClassification.from_pretrained(f'{CFG.model_path}uspppm_{fold}', num_labels=1)\n    \n    # create a Trainer instance with the loaded model and tokenizer\n    trainer = Trainer(\n            model,\n            tokenizer=tokenizer\n        )\n    \n    # make predictions on the test data using the Trainer instance\n    outputs = trainer.predict(te_dataset)\n    \n    # reshape the predictions to a 1D array\n    prediction = outputs.predictions.reshape(-1)\n    \n    # append the predictions to the list of predictions\n    predictions.append(prediction)\n    \n# take the mean of the predictions across all folds\npredictions = np.mean(predictions, axis=0)\n\n# create a new dataset containing the submission data\nsubmission = datasets.Dataset.from_dict({\n    'id': test_df['id'],\n    'score': predictions,\n})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}